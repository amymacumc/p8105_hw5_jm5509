---
title: "p8105_hw5_jm5509"
author: "Echo"
date: "2022-11-05"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
```

## Problem 2

Then I created a city_state variable.
```{r}
homicides_df <- read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

homicides_df <-  homicides_df %>% 
  mutate(city_state = str_c(city, state, sep = ', ')) 
```

I summarize within cities to obtain the total number of homicides.
```{r}
homicides_total <- 
  homicides_df %>% 
  group_by(city_state) %>% 
  summarize(n_total = n())
```


Then I summarize within cities, but this time to obtain **the number of unsolved homicides** (those for which the disposition is “Closed without arrest” or “Open/No arrest”).
```{r}
homicides_unsolved <- 
  homicides_df %>% 
  filter(disposition == 'Closed without arrest' | 
           disposition == 'Open/No arrest') %>% 
  group_by(city_state) %>% 
  summarize(n_unsolved = n())
```

Then join the two data frames together:
```{r}
homicides_table <- left_join(homicides_total, homicides_unsolved, by = 'city_state')
homicides_table[is.na(homicides_table)] <- 0
homicides_table %>% knitr::kable()
```

For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.
```{r}
baltimore_df <- homicides_df %>% 
  filter(city_state == 'Baltimore, MD')

(baltimore_total <- baltimore_df %>% nrow())
(baltimore_unsolved <- baltimore_df %>% 
  filter(disposition == 'Closed without arrest' | 
           disposition == 'Open/No arrest') %>% 
  nrow())

baltimore_test <- prop.test(baltimore_unsolved, baltimore_total)

baltimore_test %>% broom::tidy() %>% 
  select(estimate, conf.low, conf.high) %>% 
  knitr::kable(digits = 3)

```

Then I run `prop.test` for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of `purrr::map`, `purrr::map2`, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.
```{r}
homicides_stats <- 
  homicides_table %>% 
  mutate(prop_test = map2(n_unsolved, n_total, prop.test)) %>% 
  mutate(prop_test = map(prop_test, broom::tidy))%>% 
  unnest() %>% 
  select(city_state, estimate, conf.low, conf.high) 
homicides_stats %>% knitr::kable(digits = 3)
```
Create a plot that shows the estimates and CIs for each city – check out `geom_errorbar` for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r}
homicides_stats %>% 
  mutate(city_state = fct_reorder(city_state, desc(estimate))) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(text = element_text(size = 10),
          axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(
    title = 'Estimates and CIs of Unsolved Homicides by Cities'
  )
  
```

## Problem 3
First I write the function to set the simulation model: to perform t-test for data simulated in normal distribution, and the output is the estimate and the p-value.
```{r}
sim_t_test <- function(n = 30, mu = 0, sigma = 5){
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  sim_data %>% 
    t.test() %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
}
```

Generate 5000 datasets from the model:

```{r}
sim_results_df_1 = 
  expand_grid(
  sample_size = 30,
  iteration = 1:5000
) %>% 
  mutate(
    estimate_df = map(sample_size, sim_t_test)
  ) %>% 
  unnest(estimate_df)
```










